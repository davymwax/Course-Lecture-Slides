---
title: | 
  | Phil/LPS 31 Introduction to Inductive Logic
  | Lecture 13
author: |
    | David Mwakima
    | dmwakima@uci.edu
    | Department of Logic and Philosophy of Science
    | University of California, Irvine
date: "May 17th 2023"
output: beamer_presentation
header-includes:
  - \setbeamertemplate{footline}[page number]
---

# Topics

\begin{itemize}
\item Odds
\item Expected Value (Discrete Case Only)
\end{itemize}

# Recap: Probability Rules

\begin{itemize}
\item[Rule 1] $P(S) = 1$ 
\item[Rule 2] $0 \leq P(E) \leq 1$ 
\item[Rule 3] If $E \cap F = \emptyset$, then $P(E \cup F) = P(E) + P(F)$ (Special Disjunction Rule)
\item[Rule 4] $P(E \cup E^{c}) = 1$ 
\item[Rule 5] $P(E^c) = 1 - P(E)$
\item[Rule 6] $P(\emptyset) = 0$ 
\item[Rule 7] $P(E) = P(E \cap F) + P(E \cap F^{c})$
\item[Rule 8] $P(E \cup F) = P(E) + P(F) - P(E \cap F)$ (General Disjunction Rule)
\item[Rule 9] $P(E \cap F) = P(E) \times P(F)$ if $E$ and $F$ are independent.
\item[Rule 10] $P(E \cap F) = P(E) \times P(F | E)$ if $E$ and $F$ are dependent.
\end{itemize}

# Recap: Conditional Probability & Bayes' Theorem

>- Conditional Probability. This is a consequence of Rule 10:

\[
P(E \,| \,F) = \frac{P(E \cap F)}{P(F)}
\]

>- Bayes' Theorem
\[
\begin{aligned}
P(E \,|\, F) &= \frac{P(F | E)P(E)}{P(F)} \\
             &= \frac{P(F | E) P(E)}{P(F\,|\,E)P(E) + P(F\,|E^c )P(E^c)}
\end{aligned}
\]

>- A slightly more general form of Bayes Theorem says that if $\{E_{1}, E_{2}, E_{3}, E_{4}, \dots, E_{n}\}$ is a partition of $S$, then for any $E_{i} \subset S$: \begin{center} \[
\boxed{
P(E_{i} \,| \, F) = \frac{P(F | E_{i}) P(E_{i})}{\sum_{i = 1}^{n}P(F|E_{i})P(E_{i})}
}
\]
\end{center}


# Alternative ways of talking about chance

>- There are other ways that people talk about chances that are related to \textcolor{red}{but different} from probability. Let's talk about that today. 

>- Consider the following sentences: 
\begin{itemize}
\item The \textcolor{red}{odds} are 3 to 2 in favor of Mage winning the 2023 Kentucky Derby. 
\item The \textcolor{red}{odds are fifty fifty} that Real Madrid will beat Manchester City in the Champions League Semi-Final Today.
\end{itemize}

>- Odds are a useful way of talking about the chances of an event and many people often go back and forth between probability and odds as if they mean the same thing. They don't!

>- In this lecture we will see why and also introduce ways of going (1) from probability to odds and (2) from odds to probability.

# From Probabilities to Odds

>- If the probability of an event $E$ is $p$, then we know by Rule 5, that the probability of $E^{c}$ is $1 - p$. 

>- We define the \textcolor{red}{odds in favor} of E, or simply just \textcolor{red}{odds} of $E$, as: \[
\mathcal{O}(E) = \frac{p}{1 - p}
\]

>- We write $\mathcal{O}(E) = p:1 - p$ and read this as "Odds in favor of $E$ are p to 1 - p".

>- Examples. Calculate the odds in favor of the following events.\begin{itemize}
\item[(1)] The odds of Manchester City winning if the probability that Manchester City will win after being ahead 2 - 0 at half time is 0.8.
\item[(2)] The odds of having two girls, if the probability that a family has two children who are both girls is $\frac{1}{4}$. 
\end{itemize}

# From Probabilities to Odds

>- Some properties of odds: \begin{itemize} 
\item[(1)] $\mathcal{O}(E)$ can be any real number in the interval $[0, +\infty)$.
\item[(2)] If $\mathcal{O}(E)$ > 1, then $P(E) > P(E^{c})$
\item[(3)] If $\mathcal{O}(E)$ < 1, then $P(E) < P(E^{c})$
\item[(4)] If $\mathcal{O}(E) = 1$, then $P(E) = P(E^{c})$
\item[(5)] $\mathcal{O}(E)$ is invariant to scaling.
\item[(6)] $\mathcal{O}(E^{c})$, read as "odds against $E$" is given by the reciprocal of $\mathcal{O}(E)$
\end{itemize}

>- Exercise. What are the ways that probabilities are different from odds given these properties of odds?

# From Probabilities to Odds

>- Odds can be extremely useful if what you are interested in is \textcolor{red}{the relative likelihood} of an event $E$ and its complement $E^{c}$. 

>- Examples of complementary events are usually \textcolor{red}{binary events} like "Success" or "Failure"; "Win" or "Lose"; "Adverse Health Effect" or "No adverse Effect".

>- Later in the course we will see that on the Bayesian interpretation of probability, odds provide a useful way of going from fair bets (based on odds) to probabilities as \textcolor{red}{degrees of belief}.

>- We will see later that the \textcolor{red}{Odds Ratio} provides a good measure of association (or dependence) between two groups in the same way that we used joint and marginal probabilities to assess independence between groups.

# From odds to probabilities

>- Going from odds to probabilities we just reverse the operations.

>- Recall that: \[
\mathcal{O}(E) = \frac{p}{1 - p}
\]

>- Solving this equation for $p$ we get:
\[
p = \frac{\mathcal{O}(E)}{1 + \mathcal{O}(E)}
\]

# From odds to probabilities

>- Exercise. Given the following odds find the probability of the following events. \begin{itemize} \item[(1)] The odds of Real Madrid making it to the final after being 3 - 0 down at the 80th minute is 1:9.
\item[(2)] There are even odds of getting a head after tossing a coin once.
\end{itemize}

>- See \textcolor{red}{Homework 7} for more exercises.


# Expected Value (Discrete Case)

>- The number of telephone calls received at a remote call center per minute show the following frequencies:
\begin{center}
\begin{tabular}{c c}\hline
Number of Calls & Count \\ \hline
1 & 10\\
2 & 8\\
3 & 4\\
4 & 4\\
5 & 2\\
6 & 2\\
7 & 1\\
8 & 1 \\ \hline
TOTAL & 32 \\
\hline
\end{tabular}
\end{center}

# Expected Value (Discrete Case)

>- The number of calls received per minute at a remote call center is called \textcolor{red}{a random variable}. 

>- What is a random variable? A random variable has a technical definition that we shall not consider in this class. But! Let me mention that a random variable is neither a variable nor "random", whatever that means.

>- For our purposes it is enough to think that whenever we have an event that can occur with different probabilities, we can \textcolor{red}{model} the \textcolor{red}{number of occurrences} of that event using a \textcolor{red}{probability distribution}

>- Using the probability distribution, we can then ask useful questions such as: what is the \textcolor{red}{expected value} or \textcolor{red}{expectation} of the random variable.

# Expected Value (Discrete Case)

>- The expected value $E(X)$, "read as the expected value of a random variable $X$, can be helpfully thought of as the \textcolor{red}{average} or \textcolor{red}{mean} of $X$.

>- In fact $E(X)$ is \textcolor{red}{a weighted average}, where we weigh each possible value of $X$, $x_{i}$ say, by its probability $p_{i}$. 

>- For example, in the call center example, we can let the number of calls received at the center be a random variable $X$. We can calculate its expected value of the number of calls received per minute in two ways. Let's do that.

>- Here is the data for your convenience.

# Expected Value (Discrete Case)

\begin{center}
\begin{tabular}{c c}\hline
Number of Calls & Count \\ \hline
1 & 10\\
2 & 8\\
3 & 4\\
4 & 4\\
5 & 2\\
6 & 2\\
7 & 1\\
8 & 1 \\ \hline
TOTAL & 32 \\
\hline
\end{tabular}
\end{center}


# Expected Value (Discrete Case)

>- Let $\{ a_{1}, a_{2}, a_{3}, \dots, a_{n} \}$ be the possible values that a random variable $A$ can take and let $\{ p_{1}, p_{2}, p_{3}, \dots, p_{n}\}$ be the probabilities that it takes on these values.

>- The \textcolor{red}{expected value} of $A$ is given by:
\[
\begin{aligned}
E(A) &= a_{1}p_{1} + a_{2}p_{2} + a_{3}p_{3} + \dots + a_{n}p_{n} \\
    &= \sum_{i = 1}^{n} a_{i}p_{i}
\end{aligned}
\]

>- Commit this formula to memory!









